# ğŸ“ Ghi chÃº Machine Learning - Report Week 2

## 1. Supervised Learning (Há»c cÃ³ giÃ¡m sÃ¡t)

**Äá»‹nh nghÄ©a:** PhÆ°Æ¡ng phÃ¡p há»c mÃ¡y mÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n qua táº­p dá»¯ liá»‡u cÃ³ nhÃ£n (labeled data). Má»¥c tiÃªu lÃ  tÃ¬m ra hÃ m Ã¡nh xáº¡ tá»« Input ($X$) sang Output ($y$) Ä‘á»ƒ dá»± Ä‘oÃ¡n dá»¯ liá»‡u má»›i.

### Quy trÃ¬nh xá»­ lÃ½:
1.  **Thu tháº­p & GÃ¡n nhÃ£n dá»¯ liá»‡u:** Tá»•ng há»£p thÃ´ng tin thÃ nh dataset vÃ  gÃ¡n nhÃ£n.
2.  **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing):**
    * *Xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u:* XÃ³a bá» hoáº·c Ä‘iá»n giÃ¡ trá»‹ trung bÃ¬nh.
    * *Xá»­ lÃ½ dá»¯ liá»‡u nhiá»…u/ngoáº¡i lai:* XÃ³a bá» hoáº·c Ä‘iá»n giÃ¡ trá»‹ tráº§n/sÃ n.
    * *MÃ£ hÃ³a dá»¯ liá»‡u:*
        * MÃ£ hÃ³a nhÃ£n (Label Encoding): DÃ¹ng cho dá»¯ liá»‡u cÃ³ thá»© tá»±.
        * One-hot encoding: DÃ¹ng cho dá»¯ liá»‡u khÃ´ng thá»© tá»± (vÃ­ dá»¥: N, a, y, n -> vector 0/1).
    * *Chuáº©n hÃ³a dá»¯ liá»‡u:*
        * Normalization (Max-Min scaling): NÃ©n dá»¯ liá»‡u vá» Ä‘oáº¡n [0, 1].
        * Standardization (Z-score scaling): ÄÆ°a vá» phÃ¢n phá»‘i chuáº©n (mean=0), giÃ¡ trá»‹ >3 thÆ°á»ng lÃ  outlier.
3.  **Chia Dataset:**
    * *Train set:* Äá»ƒ mÃ´ hÃ¬nh há»c (95% hoáº·c 80%).
    * *Validation set:* Äá»ƒ tinh chá»‰nh mÃ´ hÃ¬nh (3% hoáº·c láº¥y tá»« train set).
    * *Test set:* Äá»ƒ kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng (2% hoáº·c 20%).
4.  **Training:** Huáº¥n luyá»‡n mÃ´ hÃ¬nh, cáº­p nháº­t trá»ng sá»‘ Ä‘á»ƒ giáº£m thiá»ƒu sai sá»‘.
5.  **ÄÃ¡nh giÃ¡ (Evaluation):** DÃ¹ng cÃ¡c chá»‰ sá»‘ nhÆ° Accuracy, Confusion Matrix, MAE, MSE, F1 score...
6.  **Tá»‘i Æ°u (Optimization):** Tinh chá»‰nh siÃªu tham sá»‘ (hyperparameters).
7.  **Triá»ƒn khai & GiÃ¡m sÃ¡t:** ÄÆ°a vÃ o thá»±c táº¿ vÃ  cáº­p nháº­t liÃªn tá»¥c.

### PhÃ¢n biá»‡t Classification & Regression:
* **Classification (PhÃ¢n loáº¡i):** NhÃ£n Ä‘áº§u ra lÃ  biáº¿n rá»i ráº¡c (VÃ­ dá»¥: Spam/Not Spam).
* **Regression (Há»“i quy):** NhÃ£n Ä‘áº§u ra lÃ  biáº¿n liÃªn tá»¥c (VÃ­ dá»¥: Dá»± Ä‘oÃ¡n giÃ¡ nhÃ ).

---

## 2. Unsupervised Learning (Há»c khÃ´ng giÃ¡m sÃ¡t)

**Äá»‹nh nghÄ©a:** LÃ m viá»‡c vá»›i dá»¯ liá»‡u khÃ´ng nhÃ£n (unlabeled data) Ä‘á»ƒ tÃ¬m cáº¥u trÃºc áº©n hoáº·c gom nhÃ³m dá»¯ liá»‡u.

**Má»¥c tiÃªu & á»¨ng dá»¥ng:** PhÃ¢n khÃºc khÃ¡ch hÃ ng, gá»£i Ã½ sáº£n pháº©m, phÃ¡t hiá»‡n gian láº­n...

### PhÃ¢n loáº¡i chÃ­nh:
* **Clustering (PhÃ¢n cá»¥m):** Gom cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u giá»‘ng nhau (VÃ­ dá»¥: K-Means, DBSCAN).
* **Dimensionality Reduction (Giáº£m chiá»u):** Giáº£m sá»‘ lÆ°á»£ng biáº¿n Ä‘áº§u vÃ o nhÆ°ng giá»¯ thÃ´ng tin quan trá»ng (VÃ­ dá»¥: PCA, t-SNE).

---

## 3. So sÃ¡nh Supervised vs Unsupervised Learning

| TiÃªu chÃ­ | Supervised Learning | Unsupervised Learning |
| :--- | :--- | :--- |
| **Dá»¯ liá»‡u Ä‘áº§u vÃ o** | CÃ³ nhÃ£n (Input $X$, Output $y$) | KhÃ´ng nhÃ£n (Chá»‰ cÃ³ Input $X$) |
| **Má»¥c tiÃªu** | Dá»± Ä‘oÃ¡n káº¿t quáº£ (Prediction) | KhÃ¡m phÃ¡ cáº¥u trÃºc (Discovery) |
| **Äá»™ phá»©c táº¡p** | Dá»… Ä‘Ã¡nh giÃ¡ hÆ¡n (cÃ³ Ground Truth) | KhÃ³ Ä‘Ã¡nh giÃ¡ hÆ¡n |
| **Thuáº­t toÃ¡n** | Linear Reg, SVM, Decision Tree... | K-Means, PCA, Apriori... |

---

## 4. CÃ¡c thuáº­t toÃ¡n tiÃªu biá»ƒu

### Supervised:
* **Linear Regression:** TÃ¬m Ä‘Æ°á»ng tháº³ng/máº·t pháº³ng khá»›p nháº¥t vá»›i dá»¯ liá»‡u liÃªn tá»¥c.
* **Logistic Regression:** PhÃ¢n loáº¡i xÃ¡c suáº¥t (thÆ°á»ng lÃ  nhá»‹ phÃ¢n) dÃ¹ng hÃ m Sigmoid.
* **Decision Tree:** Ra quyáº¿t Ä‘á»‹nh dá»±a trÃªn quy táº¯c if-else dáº¡ng cÃ¢y.
* **SVM (Support Vector Machine):** TÃ¬m siÃªu pháº³ng phÃ¢n chia cÃ¡c lá»›p vá»›i lá» (margin) lá»›n nháº¥t.
* **KNN (K-Nearest Neighbors):** PhÃ¢n loáº¡i dá»±a trÃªn "báº§u cá»­" cá»§a $k$ Ä‘iá»ƒm lÃ¢n cáº­n.

### Unsupervised:
* **K-Means:** PhÃ¢n chia dá»¯ liá»‡u thÃ nh $K$ cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch Ä‘áº¿n tÃ¢m cá»¥m.
* **DBSCAN:** PhÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™ (tá»‘t cho dá»¯ liá»‡u nhiá»…u/hÃ¬nh dáº¡ng phá»©c táº¡p).
* **PCA (Principal Component Analysis):** Chiáº¿u dá»¯ liá»‡u sang khÃ´ng gian Ã­t chiá»u hÆ¡n, giá»¯ phÆ°Æ¡ng sai lá»›n nháº¥t.